{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: May 20 2022 19:44:17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"Test script for single agent problems.\n",
    "\n",
    "This scripts runs the best model found by one of the executions of `singleagent.py`\n",
    "\n",
    "Example\n",
    "-------\n",
    "To run the script, type in a terminal:\n",
    "\n",
    "    $ python test_singleagent.py --exp ./results/save-<env>-<algo>-<obs>-<act>-<time_date>\n",
    "\n",
    "\"\"\"\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import re\n",
    "import numpy as np\n",
    "import gym\n",
    "import pprint\n",
    "import torch\n",
    "\n",
    "from gym_pybullet_drones.utils.utils import sync\n",
    "from gym_pybullet_drones.utils.Logger import Logger\n",
    "from gym_pybullet_drones.envs.single_agent_rl import NavigateLandAviary\n",
    "from gym_pybullet_drones.envs.single_agent_rl import CrossObstaclesAviary\n",
    "from gym_pybullet_drones.envs.single_agent_rl import map_name_to_env\n",
    "\n",
    "from gym_pybullet_drones.envs.single_agent_rl.BaseSingleAgentAviary import (\n",
    "    ActionType,\n",
    "    ObservationType,\n",
    ")\n",
    "import pybullet as p\n",
    "#from gym_pybullet_drones.envs.multi_agent_rl import MultiCrossObstaclesAviary\n",
    "\n",
    "import shared_constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'tag'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m ACT \u001b[39m=\u001b[39m ActionType[\u001b[39m\"\u001b[39m\u001b[39mRPM\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#### Evaluate the model ####################################\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     env_name,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     aggregate_phy_steps\u001b[39m=\u001b[39;49mshared_constants\u001b[39m.\u001b[39;49mAGGR_PHY_STEPS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     obs\u001b[39m=\u001b[39;49mOBS,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     act\u001b[39m=\u001b[39;49mACT,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     gui\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m#difficulty=16,\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     num_drones\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/mtrang/Documents/vt/research/multiagent-pybullet-drones/experiments/learning/cross_obstacles.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m env\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/anaconda3/envs/drones/lib/python3.8/site-packages/gym/envs/registration.py:235\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake\u001b[39m(\u001b[39mid\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 235\u001b[0m     \u001b[39mreturn\u001b[39;00m registry\u001b[39m.\u001b[39;49mmake(\u001b[39mid\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/drones/lib/python3.8/site-packages/gym/envs/registration.py:129\u001b[0m, in \u001b[0;36mEnvRegistry.make\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mMaking new env: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, path)\n\u001b[1;32m    128\u001b[0m spec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspec(path)\n\u001b[0;32m--> 129\u001b[0m env \u001b[39m=\u001b[39m spec\u001b[39m.\u001b[39;49mmake(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    130\u001b[0m \u001b[39mreturn\u001b[39;00m env\n",
      "File \u001b[0;32m~/anaconda3/envs/drones/lib/python3.8/site-packages/gym/envs/registration.py:90\u001b[0m, in \u001b[0;36mEnvSpec.make\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m load(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mentry_point)\n\u001b[0;32m---> 90\u001b[0m     env \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwargs)\n\u001b[1;32m     92\u001b[0m \u001b[39m# Make the environment aware of which spec it came from.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m spec \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/vt/research/multiagent-pybullet-drones/gym_pybullet_drones/envs/multi_agent_rl/MultiCrossObstaclesAviary.py:127\u001b[0m, in \u001b[0;36mMultiCrossObstaclesAviary.__init__\u001b[0;34m(self, drone_model, num_drones, neighbourhood_radius, initial_xyzs, initial_rpys, physics, freq, aggregate_phy_steps, gui, record, obs, act, reward_components, term_components, bounds, collision_detection, tag)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m initial_xyzs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[39m# [[-0.5, 0, 0.5], [-0.5, 2.5, 0.5]]\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     initial_xyzs \u001b[39m=\u001b[39m [[\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m, \u001b[39m2.5\u001b[39m \u001b[39m*\u001b[39m i, \u001b[39m0.5\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_drones)]\n\u001b[0;32m--> 127\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    128\u001b[0m     drone_model\u001b[39m=\u001b[39;49mdrone_model,\n\u001b[1;32m    129\u001b[0m     num_drones\u001b[39m=\u001b[39;49mnum_drones,\n\u001b[1;32m    130\u001b[0m     neighbourhood_radius\u001b[39m=\u001b[39;49mneighbourhood_radius,\n\u001b[1;32m    131\u001b[0m     initial_xyzs\u001b[39m=\u001b[39;49minitial_xyzs,\n\u001b[1;32m    132\u001b[0m     initial_rpys\u001b[39m=\u001b[39;49minitial_rpys,\n\u001b[1;32m    133\u001b[0m     physics\u001b[39m=\u001b[39;49mphysics,\n\u001b[1;32m    134\u001b[0m     freq\u001b[39m=\u001b[39;49mfreq,\n\u001b[1;32m    135\u001b[0m     aggregate_phy_steps\u001b[39m=\u001b[39;49maggregate_phy_steps,\n\u001b[1;32m    136\u001b[0m     gui\u001b[39m=\u001b[39;49mgui,\n\u001b[1;32m    137\u001b[0m     record\u001b[39m=\u001b[39;49mrecord,\n\u001b[1;32m    138\u001b[0m     obs\u001b[39m=\u001b[39;49mobs,\n\u001b[1;32m    139\u001b[0m     act\u001b[39m=\u001b[39;49mact,\n\u001b[1;32m    140\u001b[0m     tag\u001b[39m=\u001b[39;49mtag,\n\u001b[1;32m    141\u001b[0m )\n\u001b[1;32m    143\u001b[0m \u001b[39m# override base aviary episode length\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mEPISODE_LEN_SEC \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'tag'"
     ]
    }
   ],
   "source": [
    "\n",
    "#env_name = \"land-aviary-v0\"\n",
    "env_name = \"multicrossobs-aviary-v0\"\n",
    "# env_name = \"long-cross-obs-aviary-v0\"\n",
    "# env_name = \"cross-obstacles-aviary-v0\"\n",
    "\n",
    "OBS = (\n",
    "    ObservationType[\"KIN\"]\n",
    ")\n",
    "ACT = ActionType[\"RPM\"]\n",
    "#### Evaluate the model ####################################\n",
    "env = gym.make(\n",
    "    env_name,\n",
    "    aggregate_phy_steps=shared_constants.AGGR_PHY_STEPS,\n",
    "    obs=OBS,\n",
    "    act=ACT,\n",
    "    gui=True,\n",
    "    #difficulty=16,\n",
    "    num_drones=6,\n",
    ")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = {\"__all__\": False}\n",
    "while not done[\"__all__\"]:\n",
    "    env.render()\n",
    "    action = env.action_space.sample()\n",
    "    time.sleep(0.05)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    if done[\"__all__\"]:\n",
    "        env.reset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.loadURDF(\"cube.urdf\", [0, 0, 0.5], physicsClientId=env.CLIENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Single Step of env and print state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "action = env.action_space.sample()\n",
    "for i in range(1):\n",
    "    time.sleep(0.05)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"action: {action}\")\n",
    "    print(f\"obs: {obs}\")\n",
    "    print(f\"reward: {reward}\")\n",
    "    print(f\"done: {done}\")\n",
    "    env.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "action = env.action_space.sample()\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and flip\n",
    "action = env.action_space.sample()\n",
    "print(action)\n",
    "for i in range(100):\n",
    "    time.sleep(0.05)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    #state = env.getFirstDroneState()\n",
    "    print(f\"action: {action}\")\n",
    "    print(f\"obs: {obs}\")\n",
    "    print(f\"reward: {reward}\")\n",
    "    print(f\"done: {done}\")\n",
    "    #print(f\"state: {state}\")\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "landing_zone_xyz = [3.5, 3.5, 0.0625]\n",
    "position = state[0:3]\n",
    "print(position)\n",
    "target_position = landing_zone_xyz\n",
    "pos_dist = np.linalg.norm(position[0:2] - target_position[0:2])\n",
    "print(pos_dist)\n",
    "\n",
    "y_dist = np.linalg.norm(position[2] - (target_position[2] - 0.1))\n",
    "print(y_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rpy = state[7:10]\n",
    "print(rpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change initial position of the drones\n",
    "a = p.getContactPoints(bodyA=env.DRONE_IDS[0],\n",
    "            physicsClientId=env.CLIENT\n",
    "            )\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "p.resetSimulation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('drones')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "368184befd70de6859feb7ba7ed007b2fb115c321767e95f8823607adf146467"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
